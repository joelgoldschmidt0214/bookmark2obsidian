"""
Bookmark to Obsidian Converter
Streamlitãƒ™ãƒ¼ã‚¹ã®ãƒ‡ã‚¹ã‚¯ãƒˆãƒƒãƒ—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
Google Chromeã®bookmarks.htmlãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã€Obsidianç”¨ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã™ã‚‹
"""

import datetime
import logging
import os
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path

import streamlit as st
from streamlit_autorefresh import st_autorefresh

from core.cache_manager import CacheManager
from core.file_manager import LocalDirectoryManager

# åˆ†é›¢ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from core.parser import BookmarkParser
from ui.components import (
    display_edge_case_summary,
    display_page_list_and_preview,
    handle_edge_cases_and_errors,
    show_application_info,
    validate_bookmarks_file,
    validate_directory_path,
)
from ui.progress_display import ProgressDisplay
from utils.cache_utils import clear_all_cache, get_cache_statistics
from utils.performance_utils import MemoryMonitor

# --- ãƒ­ã‚°è¨­å®š (å¤‰æ›´ãªã—) ---
log_level = logging.DEBUG if os.getenv("DEBUG") == "1" else logging.INFO
log_directory = Path("logs")
log_directory.mkdir(exist_ok=True)
log_filename = log_directory / f"bookmark2obsidian_{datetime.datetime.now().strftime('%Y%m%d')}.log"
handlers = [
    logging.StreamHandler(),
    logging.FileHandler(log_filename, encoding="utf-8"),
]
logging.basicConfig(
    level=log_level,
    format="%(asctime)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s",
    handlers=handlers,
)
logger = logging.getLogger(__name__)
logger.info(f"ğŸš€ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹å§‹ (ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«: {logging.getLevelName(log_level)})")


# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆé–¢æ•° (å¤‰æ›´ãªã—) ---
def display_performance_settings_ui():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®šUIã‚’è¡¨ç¤º"""
    st.markdown("---")
    st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š")
    batch_size = st.slider(
        "ãƒãƒƒãƒã‚µã‚¤ã‚º",
        min_value=10,
        max_value=500,
        value=st.session_state.get("batch_size", 100),
        step=10,
        help="ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã®æ•°ã€‚å¤§ããã™ã‚‹ã¨é«˜é€ŸåŒ–ã—ã¾ã™ãŒã€ãƒ¡ãƒ¢ãƒªã‚’å¤šãä½¿ç”¨ã—ã¾ã™ã€‚",
    )
    st.session_state["batch_size"] = batch_size
    use_parallel = st.checkbox(
        "ä¸¦åˆ—å‡¦ç†ã‚’ä½¿ç”¨",
        value=st.session_state.get("use_parallel_processing", True),
        help="è¤‡æ•°ã®CPUã‚³ã‚¢ã‚’ä½¿ç”¨ã—ã¦å‡¦ç†ã‚’é«˜é€ŸåŒ–ã—ã¾ã™ã€‚",
    )
    st.session_state["use_parallel_processing"] = use_parallel


def display_cache_management_ui():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†UIã‚’è¡¨ç¤º"""
    try:
        st.markdown("---")
        st.subheader("ğŸ—„ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†")
        cache_stats = get_cache_statistics()
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªæ•°", cache_stats.get("total_entries", 0))
            st.metric("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚º", f"{cache_stats.get('total_size_mb', 0.0):.1f} MB")
        with col2:
            st.metric("ãƒ’ãƒƒãƒˆç‡", f"{cache_stats.get('hit_rate', 0.0):.1f}%")
            last_cleanup = cache_stats.get("last_cleanup", "ä¸æ˜")
            st.metric(
                "æœ€çµ‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—",
                last_cleanup if isinstance(last_cleanup, str) else last_cleanup.strftime("%m/%d %H:%M"),
            )

        if st.button("ğŸ—‘ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢", help="ã™ã¹ã¦ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã™"):
            clear_all_cache()
            st.success("âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
            st.rerun()

        force_reanalysis = st.checkbox(
            "ğŸ”„ å¼·åˆ¶å†è§£æ",
            value=st.session_state.get("force_reanalysis", False),
            help="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«å†è§£æã—ã¾ã™",
        )
        st.session_state["force_reanalysis"] = force_reanalysis
    except Exception as e:
        st.error(f"âŒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†UIè¡¨ç¤ºã‚¨ãƒ©ãƒ¼: {str(e)}")


def _check_file_cache_status(uploaded_file):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        bytes_content = uploaded_file.getvalue()
        html_content_str = bytes_content.decode("utf-8")
        cache_manager = CacheManager()
        if cache_manager.load_from_cache(html_content_str):
            st.success("ğŸ—„ï¸ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æçµæœãŒã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è¦‹ã¤ã‹ã‚Šã¾ã—ãŸï¼")
            st.session_state["cache_available"] = True
        else:
            st.info("ğŸ” ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆå›è§£æã§ã™ã€‚çµæœã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜ã•ã‚Œã¾ã™ã€‚")
            st.session_state["cache_available"] = False
    except Exception as e:
        st.warning(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°"""
    st.set_page_config(page_title="Bookmark to Obsidian Converter", page_icon="ğŸ“š", layout="wide")

    # --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
    if "app_state" not in st.session_state:
        st.session_state.app_state = "initial"
    if "analysis_future" not in st.session_state:
        st.session_state.analysis_future = None
    if "progress_info" not in st.session_state:
        st.session_state.progress_info = {}
    if "performance_stats" not in st.session_state:
        st.session_state.performance_stats = {}

    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
    with st.sidebar:
        st.header("ğŸ”§ è¨­å®š")
        uploaded_file = st.file_uploader("bookmarks.htmlã‚’é¸æŠ", type=["html"])
        if uploaded_file:
            st.session_state["uploaded_file"] = uploaded_file
            is_valid, msg = validate_bookmarks_file(uploaded_file)
            st.session_state["file_validated"] = is_valid
            if is_valid:
                st.success(msg)
                _check_file_cache_status(uploaded_file)
            else:
                st.error(msg)
        else:
            st.session_state["file_validated"] = False

        default_path = st.session_state.get(
            "output_directory_str", "/mnt/d/hasechu/OneDrive/ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ/Obsidian/hase_main/bookmarks"
        )  # os.path.expanduser("~"))
        directory_path = st.text_input("ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª", value=default_path)
        if directory_path:
            st.session_state["output_directory_str"] = directory_path
            is_valid, msg = validate_directory_path(directory_path)
            st.session_state["directory_validated"] = is_valid
            if is_valid:
                st.success(msg)
                st.session_state["output_directory"] = Path(directory_path)
            else:
                st.error(msg)
        else:
            st.session_state["directory_validated"] = False

        st.markdown("---")
        st.subheader("âš™ï¸ è¨­å®šçŠ¶æ³")
        file_status = "âœ… å®Œäº†" if st.session_state.get("file_validated") else "âŒ æœªå®Œäº†"
        dir_status = "âœ… å®Œäº†" if st.session_state.get("directory_validated") else "âŒ æœªå®Œäº†"
        st.markdown(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ: {file_status}\n\nğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé¸æŠ: {dir_status}")

        ready_to_proceed = st.session_state.get("file_validated") and st.session_state.get("directory_validated")
        if st.button("ğŸ“Š ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯è§£æã‚’é–‹å§‹", type="primary", disabled=not ready_to_proceed):
            st.session_state.app_state = "parsing"
            keys_to_clear = [
                "bookmarks",
                "analysis_stats",
                "duplicates",
                "edge_case_result",
                "analysis_future",
                "progress_info",
            ]
            for key in keys_to_clear:
                st.session_state.pop(key, None)
            st.rerun()

        display_cache_management_ui()
        display_performance_settings_ui()
        with st.expander("â„¹ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±"):
            show_application_info()

    # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒªã‚¢ ---
    st.title("ğŸ“š Bookmark to Obsidian Converter")
    st.markdown("Chromeã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã€Obsidianç”¨ã®Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

    if st.session_state.app_state == "initial":
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã€ã€Œãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯è§£æã‚’é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

    elif st.session_state.app_state == "parsing":
        handle_parsing_state()

    elif st.session_state.app_state == "results":
        handle_results_state()


def handle_parsing_state():
    """è§£æä¸­ã®çŠ¶æ…‹ã‚’å‡¦ç†ã™ã‚‹"""
    if st.session_state.analysis_future is None:
        with ThreadPoolExecutor(max_workers=1) as executor:
            st.session_state.executor = executor
            bytes_content = st.session_state.uploaded_file.getvalue()
            html_content_str = bytes_content.decode("utf-8")
            cache_manager = CacheManager()
            future = executor.submit(execute_optimized_bookmark_analysis, html_content_str, cache_manager)
            st.session_state.analysis_future = future

    future = st.session_state.analysis_future

    if "progress_display" not in st.session_state:
        st.session_state.progress_display = ProgressDisplay(title="ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯è§£æé€²æ—")

    progress_display = st.session_state.progress_display
    total_items = st.session_state.progress_info.get("total", 1)
    progress_display.initialize_display(total_items)

    if future.done():
        try:
            result = future.result()
            st.session_state.performance_stats = result["analysis_stats"]
            st.session_state.bookmarks = result["bookmarks"]
            st.session_state.analysis_stats = result["analysis_stats"]
            with st.spinner("é‡è¤‡ãƒã‚§ãƒƒã‚¯ã¨æœ€çµ‚å‡¦ç†ä¸­..."):
                directory_manager = LocalDirectoryManager(st.session_state["output_directory"])
                directory_manager.scan_directory()
                st.session_state.directory_manager = directory_manager
                st.session_state.duplicates = directory_manager.compare_with_bookmarks(result["bookmarks"])
                st.session_state.edge_case_result = handle_edge_cases_and_errors(result["bookmarks"])

            st.session_state.app_state = "results"
            st.session_state.analysis_future = None
            st.rerun()
        except Exception as e:
            st.error(f"è§£æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            logger.error("è§£æãƒ•ãƒ¥ãƒ¼ãƒãƒ£ãƒ¼ã®å–å¾—ã§ã‚¨ãƒ©ãƒ¼", exc_info=True)
            st.session_state.app_state = "initial"
    else:
        # st.session_stateã‹ã‚‰é€²æ—ã‚’èª­ã¿å–ã‚ŠUIã‚’æ›´æ–°
        progress_info = st.session_state.get("progress_info", {})
        processed = progress_info.get("current", 0)
        total = progress_info.get("total", 1)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã‚’æ›´æ–°
        mem_monitor = st.session_state.get("mem_monitor")
        memory_usage = mem_monitor.get_memory_usage_mb() if mem_monitor else 0

        progress_display.update_progress(
            completed=processed, current_item=f"{processed}/{total} ä»¶å‡¦ç†ä¸­", memory_usage_mb=memory_usage
        )
        st_autorefresh(interval=1000, limit=None, key="progress_refresh")


def handle_results_state():
    """è§£æçµæœã®è¡¨ç¤ºçŠ¶æ…‹ã‚’å‡¦ç†ã™ã‚‹"""
    bookmarks = st.session_state.bookmarks
    duplicates = st.session_state.duplicates
    directory_manager = st.session_state.directory_manager

    if not bookmarks:
        st.warning("âš ï¸ æœ‰åŠ¹ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    stats = st.session_state.analysis_stats
    st.success(
        f"è§£æå®Œäº†ï¼ {stats['bookmark_count']}ä»¶ã®ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã‚’{stats['parse_time']:.2f}ç§’ã§å‡¦ç†ã—ã¾ã—ãŸã€‚",
        f" (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {stats['cache_hit']})",
    )

    # --- âœ¨ä¿®æ­£ç‚¹: st.tabsã‚’ä½¿ç”¨ã—ã¦UIã‚’æ•´ç† ---
    tab1, tab2, tab3 = st.tabs(["ğŸ“Š æ¦‚è¦", "ğŸ“‚ ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ä¸€è¦§", "âš ï¸ ç‰¹æ®Šã‚±ãƒ¼ã‚¹"])

    with tab1:
        st.subheader("è§£æçµæœã‚µãƒãƒªãƒ¼")
        dir_stats = directory_manager.get_statistics()
        parser = BookmarkParser()
        bookmark_stats = parser.get_statistics(bookmarks)

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“š ç·ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯æ•°", bookmark_stats["total_bookmarks"])
        with col2:
            st.metric("ğŸŒ ãƒ¦ãƒ‹ãƒ¼ã‚¯ãƒ‰ãƒ¡ã‚¤ãƒ³æ•°", bookmark_stats["unique_domains"])
        with col3:
            st.metric("ğŸ“ ãƒ•ã‚©ãƒ«ãƒ€æ•°", bookmark_stats["folder_count"])
        with col4:
            st.metric("ğŸ”„ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«æ•°", dir_stats["duplicate_files"])

        st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ")
        perf_stats = st.session_state.performance_stats
        p_col1, p_col2, p_col3 = st.columns(3)
        with p_col1:
            st.metric("â±ï¸ å‡¦ç†æ™‚é–“", f"{perf_stats.get('parse_time', 0):.2f} ç§’")
        with p_col2:
            st.metric("ğŸ§  ãƒ”ãƒ¼ã‚¯ãƒ¡ãƒ¢ãƒª", f"{perf_stats.get('peak_memory_mb', 0):.1f} MB")
        with p_col3:
            st.metric("âš¡ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ", "âœ… Yes" if perf_stats.get("cache_hit") else "âŒ No")

    with tab2:
        display_page_list_and_preview(bookmarks, duplicates, st.session_state["output_directory"])

    with tab3:
        if "edge_case_result" in st.session_state:
            display_edge_case_summary(st.session_state["edge_case_result"], show_details=True)


def execute_optimized_bookmark_analysis(html_content_str: str, cache_manager: CacheManager):
    """æœ€é©åŒ–ã•ã‚ŒãŸãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯è§£æã‚’å®Ÿè¡Œï¼ˆUIæ“ä½œã‹ã‚‰åˆ†é›¢ï¼‰"""
    start_time = time.time()
    mem_monitor = MemoryMonitor()
    st.session_state["mem_monitor"] = mem_monitor

    # --- âœ¨ä¿®æ­£ç‚¹: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æ¸¡ã™ã‚ˆã†ã«ä¿®æ­£ ---
    def progress_callback(current, total, message=""):
        st.session_state.progress_info = {"current": current, "total": total, "message": message}

    try:
        bookmarks, cache_hit = None, False

        if not st.session_state.get("force_reanalysis", False):
            cached_bookmarks = cache_manager.load_from_cache(html_content_str)
            if cached_bookmarks:
                bookmarks, cache_hit = cached_bookmarks, True
                progress_callback(1, 1, "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿å®Œäº†")  # é€²æ—ã‚’100%ã«

        if bookmarks is None:
            parser = BookmarkParser()  # rules.ymlã®ãƒ‘ã‚¹ã¯å¿…è¦ã«å¿œã˜ã¦æŒ‡å®š
            bookmarks = parser.parse(html_content_str)
            cache_manager.save_to_cache(html_content_str, bookmarks)
            # parseã®çµæœã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Œã°ã“ã“ã§è¡Œã†
            # filtered_bookmarks = [b for b in bookmarks if not parser._should_exclude_bookmark(b)]
            # bookmarks = filtered_bookmarks

        unique_bookmarks_dict = {b.url: b for b in reversed(bookmarks)}
        bookmarks = list(unique_bookmarks_dict.values())

        parse_time = time.time() - start_time
        peak_memory = mem_monitor.get_memory_delta()

        analysis_stats = {
            "parse_time": parse_time,
            "cache_hit": cache_hit,
            "bookmark_count": len(bookmarks),
            "peak_memory_mb": peak_memory,
        }
        return {"bookmarks": bookmarks, "analysis_stats": analysis_stats}
    except Exception:
        logger.error("ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯è§£æã®ã‚¹ãƒ¬ãƒƒãƒ‰ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", exc_info=True)
        raise


if __name__ == "__main__":
    main()
